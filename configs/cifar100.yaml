# CIFAR-100数据集联邦学习实验配置
# 专门用于CIFAR-100数据集的联邦学习实验

# ==============================
# 实验基本设置
# ==============================
experiment:
  name: "cifar100_federated_learning"      # 实验名称
  rounds: 30                               # CIFAR-100需要更多轮数收敛（100个类别）
  seed: 42                                 # 随机种子

# ==============================
# 设备配置
# ==============================
device: "auto"  # auto: 自动检测GPU, cuda: 强制GPU, cpu: 强制CPU

# ==============================
# 学习率配置 - 统一管理所有学习率设置
# ==============================
learning_rates:
  client: 0.001                            # 客户端学习率
  server: 1.0                              # 服务器聚合学习率
  model: 0.001                             # 模型训练学习率
  optimizer: 0.001                         # 优化器学习率

# ==============================
# 分布式训练和日志配置
# ==============================
wandb:
  enabled: true                            # 启用WandB记录CIFAR-100实验
  project: "cifar100-federated-learning"   # 专门的CIFAR-100项目
  offline: true                            # 离线模式

# ==============================
# 客户端配置
# ==============================
client:
  num_clients: 5                           # 客户端数量（适合100个类别的分布）
  local_epochs: 3                          # 本地训练轮数
  
  # 客户端数据集分配 - 所有客户端使用CIFAR-100
  client_datasets:
    client_0:
      - cifar100                           # 客户端0：CIFAR-100
    client_1:
      - cifar100                           # 客户端1：CIFAR-100
    client_2:
      - cifar100                           # 客户端2：CIFAR-100
    client_3:
      - cifar100                           # 客户端3：CIFAR-100
    client_4:
      - cifar100                           # 客户端4：CIFAR-100
  
# ==============================
# 服务器配置
# ==============================
server:
  aggregation_method: "federated_avg"      # FedAvg算法

# ==============================
# 模型配置
# ==============================
model:
  type: "cnn"                              # CNN模型，适合CIFAR-100

# ==============================
# 优化器配置
# ==============================
optimizer:
  type: "adamw"                            # 优化器类型
  weight_decay: 0.01                       # 权重衰减
  betas: [0.9, 0.999]                     # Adam beta参数
  eps: 1e-8                               # 数值稳定性参数

# ==============================
# 数据集配置
# ==============================
data:
  data_dir: "/home/zzm/dataset/"           # 数据集根目录
  batch_size: 32                           # 训练批次大小
  num_workers: 2                           # 数据加载器工作进程数
  
  # 具体数据集配置
  datasets:
    cifar100:
      train: true                          # CIFAR-100训练集

# ==============================
# 评估配置
# ==============================
evaluation:
  evaluate_every: 1                        # 每轮都评估
  test_batch_size: 100                     # 测试批次大小
  metrics:                                 # 评估指标
    - "loss"
    - "accuracy"
    - "top5_accuracy"                      # CIFAR-100常用Top-5准确率

# ==============================
# 通信配置
# ==============================
communication:
  method: "local"                          # 通信方法

# ==============================
# 实验和输出配置
# ==============================
output:
  log_level: "INFO"                        # 日志级别
  save_results: true                       # 保存结果
  results_dir: "./results/"                # 结果保存目录