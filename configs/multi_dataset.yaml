# 多数据集联邦学习实验配置
# 模拟异构数据环境，不同客户端使用不同数据集

# ==============================
# 实验基本设置
# ==============================
experiment:
  name: "multi_dataset_federated_experiment"  # 实验名称
  rounds: 10                               # 联邦学习轮数
  seed: 42                                 # 随机种子

# ==============================
# 设备配置
# ==============================
device: "auto"  # auto: 自动检测GPU, cuda: 强制GPU, cpu: 强制CPU

# ==============================
# 分布式训练和日志配置
# ==============================
wandb:
  enabled: true                            # 启用WandB记录多数据集实验
  project: "federated-learning-heterogeneous"  # 专门的项目名称
  offline: true                            # 离线模式

# ==============================
# 客户端配置
# ==============================
client:
  num_clients: 4                           # 总客户端数量
  local_epochs: 5                          # 本地训练轮数
  learning_rate: 0.001                     # 客户端学习率
  
  # 客户端数据集分配 - 异构数据分布
  client_datasets:
    client_0:
      - mnist                              # 客户端0：仅MNIST
    client_1:
      - mnist                              # 客户端1：仅MNIST
    client_2:
      - cifar10                            # 客户端2：仅CIFAR-10
    client_3:
      - mnist                              # 客户端3：混合数据集
      - cifar10
  
# ==============================
# 服务器配置
# ==============================
server:
  aggregation_method: "federated_avg"      # FedAvg算法
  server_learning_rate: 1.0                # 服务器学习率

# ==============================
# 模型配置
# ==============================
model:
  type: "cnn"                              # CNN模型，需要适应多种数据集
  learning_rate: 0.001                     # 模型学习率

# ==============================
# 优化器配置
# ==============================
optimizer:
  type: "adamw"                            # 优化器类型
  learning_rate: 0.001                     # 学习率
  weight_decay: 0.01                       # 权重衰减
  betas: [0.9, 0.999]                     # Adam beta参数
  eps: 1e-8                               # 数值稳定性参数

# ==============================
# 数据集配置
# ==============================
data:
  data_dir: "/home/zzm/dataset/"           # 数据集根目录
  batch_size: 32                           # 训练批次大小
  num_workers: 2                           # 数据加载器工作进程数
  
  # 具体数据集配置
  datasets:
    mnist:
      train: true                          # MNIST训练集
    cifar10:
      train: true                          # CIFAR-10训练集

# ==============================
# 评估配置
# ==============================
evaluation:
  evaluate_every: 1                        # 每轮都评估
  test_batch_size: 100                     # 测试批次大小
  metrics:                                 # 评估指标
    - "loss"
    - "accuracy"
