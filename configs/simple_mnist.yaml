# 简单MNIST联邦学习实验配置
# 用于快速验证和调试的简化版本，客户端数量少，轮数少

# ==============================
# 实验基本设置
# ==============================
experiment:
  name: "simple_mnist_experiment"          # 实验名称
  rounds: 5                                # 较少的轮数，用于快速验证
  seed: 42                                 # 随机种子

# ==============================
# 设备配置
# ==============================
device: "auto"  # auto: 自动检测GPU, cuda: 强制GPU, cpu: 强制CPU

# ==============================
# 学习率配置 - 统一管理所有学习率设置
# ==============================
learning_rates:
  client: 0.001                            # 客户端学习率
  server: 1.0                              # 服务器聚合学习率
  model: 0.001                             # 模型训练学习率
  optimizer: 0.001                         # 优化器学习率

# ==============================
# 分布式训练和日志配置
# ==============================
wandb:
  enabled: false                           # 关闭WandB，简化调试
  project: "federated-learning"            # WandB项目名称
  offline: false                           # 不使用离线模式

# ==============================
# 客户端配置
# ==============================
client:
  num_clients: 3                           # 少量客户端，便于调试
  local_epochs: 3                          # 本地训练轮数
  # learning_rate: 使用 learning_rates.client 配置
  
  # 客户端数据集分配 - 所有客户端使用MNIST
  client_datasets:
    client_0:
      - mnist
    client_1:
      - mnist
    client_2:
      - mnist
  
# ==============================
# 服务器配置
# ==============================
server:
  aggregation_method: "federated_avg"      # FedAvg算法
  # server_learning_rate: 使用 learning_rates.server 配置

# ==============================
# 模型配置
# ==============================
model:
  type: "cnn"                              # CNN模型
  # learning_rate: 使用 learning_rates.model 配置

# ==============================
# 优化器配置
# ==============================
optimizer:
  type: "adamw"                            # 优化器类型
  # learning_rate: 使用 learning_rates.optimizer 配置
  weight_decay: 0.01                       # 权重衰减
  betas: [0.9, 0.999]                     # Adam beta参数
  eps: 1e-8                               # 数值稳定性参数

# ==============================
# 数据集配置
# ==============================
data:
  data_dir: "/home/zzm/dataset/"           # 数据集根目录
  batch_size: 64                           # 较大的批次大小，适合简单实验
  num_workers: 2                           # 数据加载器工作进程数
  
  # 具体数据集配置
  datasets:
    mnist:
      train: true                          # 使用MNIST训练集

# ==============================
# 评估配置
# ==============================
evaluation:
  evaluate_every: 1                        # 每轮都评估
  test_batch_size: 100                     # 测试批次大小
  metrics:                                 # 评估指标
    - "loss"
    - "accuracy"
