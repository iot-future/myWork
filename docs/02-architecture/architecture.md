# 框架架构

联邦学习框架采用模块化设计，确保各组件职责单一、易于扩展。

## 整体架构

```
联邦学习框架
├── 核心层 (Core Layer)
│   ├── 客户端 (Client)
│   ├── 服务器 (Server)  
│   └── 基础抽象类 (Base Classes)
├── 模型层 (Model Layer)
│   ├── 基础模型类
│   └── 具体模型实现
├── 数据层 (Data Layer)
│   ├── 数据加载器
│   └── 数据分割器
├── 通信层 (Communication Layer)
│   ├── 本地通信
│   └── 网络通信接口
├── 聚合层 (Aggregation Layer)
│   ├── FedAvg算法
│   └── 其他聚合算法接口
└── 工具层 (Utility Layer)
    ├── 日志工具
    └── 其他辅助工具
```

## 设计原则

### 1. 模块化设计
每个模块都有明确的职责边界：
- **核心层**: 负责联邦学习的基本流程控制
- **模型层**: 负责机器学习模型的定义和操作
- **数据层**: 负责数据的加载、分割和管理
- **通信层**: 负责客户端和服务器之间的数据传输
- **聚合层**: 负责模型参数的聚合算法
- **工具层**: 提供日志、配置等辅助功能

### 2. 抽象与实现分离
使用抽象基类定义接口，具体实现继承基类：
- `BaseClient` -> `FederatedClient`
- `BaseServer` -> `FederatedServer`
- `BaseModel` -> `SimpleClassificationModel`, `SimpleLinearModel`
- `BaseCommunication` -> `LocalCommunication`

### 3. 松耦合
模块间通过接口交互，降低耦合度：
- 客户端不直接依赖服务器实现
- 服务器不直接依赖特定的聚合算法
- 通信模块可以独立替换

### 4. 可扩展性
预留扩展点，便于添加新功能：
- 新的模型类型
- 新的聚合算法
- 新的通信方式
- 新的数据处理方法

## 核心工作流程

### 1. 初始化阶段
```
1. 创建服务器和全局模型
2. 创建客户端和本地模型
3. 初始化通信模块
4. 分发数据到各客户端
```

### 2. 训练阶段（每轮）
```
1. 服务器广播全局模型参数
2. 客户端接收参数并更新本地模型
3. 客户端使用本地数据训练模型
4. 客户端发送模型更新到服务器
5. 服务器聚合所有客户端更新
6. 服务器更新全局模型
```

### 3. 评估阶段
```
1. 使用测试数据评估全局模型
2. 记录性能指标
3. 决定是否继续训练
```

## 数据流图

```
┌─────────────┐    参数广播    ┌─────────────┐
│   服务器    │ ────────────► │   客户端1   │
│             │               │             │
│ 全局模型    │               │ 本地模型    │
│ 聚合算法    │               │ 本地数据    │
└─────────────┘               └─────────────┘
       ▲                             │
       │                             │ 参数更新
       │                             ▼
       │                      ┌─────────────┐
       │                      │   客户端2   │
       │                      │             │
       │                      │ 本地模型    │
       │                      │ 本地数据    │
       │                      └─────────────┘
       │                             │
    参数聚合                         │ 参数更新
       │                             ▼
       │                      ┌─────────────┐
       │                      │   客户端N   │
       │                      │             │
       │                      │ 本地模型    │
       └──────────────────────│ 本地数据    │
                              └─────────────┘
```

## 关键特性

### 1. 支持多种场景
- **IID数据分布**: 适合理想化实验
- **Non-IID数据分布**: 更接近真实场景
- **分类任务**: 支持多分类问题
- **回归任务**: 支持连续值预测

### 2. 灵活的配置
- 可配置客户端数量
- 可调整训练轮数和本地epoch数
- 支持不同的学习率和批次大小
- 可选择不同的聚合算法

### 3. 可观测性
- 详细的训练日志
- 性能指标记录
- 客户端状态监控

## 扩展点

### 1. 新模型类型
继承 `BaseModel` 实现新的机器学习模型

### 2. 新聚合算法
实现新的参数聚合策略（如FedProx、SCAFFOLD等）

### 3. 新通信方式
继承 `BaseCommunication` 实现网络通信

### 4. 新数据处理
扩展数据加载和预处理功能

### 5. 隐私保护
添加差分隐私、同态加密等隐私保护机制

这种架构设计确保了框架的可维护性、可扩展性和易用性。
