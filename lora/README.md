# LoRA æ¨¡å—

ä¸ºè”é‚¦å­¦ä¹ æ¡†æ¶æä¾› LoRA (Low-Rank Adaptation) åŠŸèƒ½æ”¯æŒçš„å®Œæ•´æ¨¡å—ã€‚

## æ¦‚è¿°

æœ¬æ¨¡å—é‡‡ç”¨**åŒ…è£…å™¨æ¨¡å¼**è®¾è®¡ï¼Œå¯ä»¥ä¸ºç°æœ‰çš„è”é‚¦å­¦ä¹ æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯CLIPæ¨¡å‹ï¼‰æ·»åŠ LoRAåŠŸèƒ½ï¼Œè€Œæ— éœ€ä¿®æ”¹åŸæœ‰ä»£ç ç»“æ„ã€‚è®¾è®¡ç›®æ ‡æ˜¯ä¸ç°æœ‰æ¡†æ¶å®Œå…¨è§£è€¦ï¼Œæä¾›å³æ’å³ç”¨çš„LoRAåŠŸèƒ½ã€‚

## ç‰¹æ€§

- ğŸ”§ **å³æ’å³ç”¨**: åŒ…è£…å™¨æ¨¡å¼ï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰æ¨¡å‹ä»£ç 
- ğŸ¯ **CLIPä¸“ç”¨**: ä¸“é—¨ä¸ºCLIPæ¨¡å‹ä¼˜åŒ–çš„LoRAé…ç½®
- ğŸ“Š **å‚æ•°é«˜æ•ˆ**: å¤§å¹…å‡å°‘å¯è®­ç»ƒå‚æ•°ï¼Œæé«˜è®­ç»ƒæ•ˆç‡
- ğŸ”„ **è”é‚¦å­¦ä¹ å…¼å®¹**: å®Œå…¨å…¼å®¹ç°æœ‰çš„è”é‚¦å­¦ä¹ å‚æ•°ç®¡ç†æ¥å£
- ğŸ’¾ **æ¨¡å‹ç®¡ç†**: æä¾›å®Œæ•´çš„LoRAæ¨¡å‹ä¿å­˜ã€åŠ è½½ã€ç®¡ç†åŠŸèƒ½
- âš™ï¸ **é…ç½®çµæ´»**: æ”¯æŒå¤šç§é¢„è®¾é…ç½®å’Œè‡ªå®šä¹‰é…ç½®

## å®‰è£…ä¾èµ–

```bash
pip install torch peft transformers
```

## æ¨¡å—ç»“æ„

```
lora/
â”œâ”€â”€ __init__.py          # æ¨¡å—å…¥å£
â”œâ”€â”€ config.py            # LoRAé…ç½®ç®¡ç†
â”œâ”€â”€ base.py              # LoRAåŸºç¡€åŒ…è£…å™¨
â”œâ”€â”€ clip_wrapper.py      # CLIPä¸“ç”¨LoRAåŒ…è£…å™¨
â”œâ”€â”€ factory.py           # LoRAæ¨¡å‹å·¥å‚å’Œç®¡ç†å™¨
â”œâ”€â”€ test_lora.py         # æµ‹è¯•è„šæœ¬
â””â”€â”€ README.md            # æœ¬æ–‡æ¡£
```

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from lora import LoRAConfig, quick_clip_lora

# å¿«é€Ÿåˆ›å»ºCLIP LoRAæ¨¡å‹
model = quick_clip_lora(
    model_name="openai/clip-vit-base-patch32",
    num_classes=10,
    lora_r=16
)

# æ¨¡å‹è®­ç»ƒå’Œä½¿ç”¨ä¸åŸå§‹FederatedCLIPModelå®Œå…¨ç›¸åŒ
```

### 2. åŒ…è£…ç°æœ‰æ¨¡å‹

```python
from models.clip import FederatedCLIPModel
from lora.clip_wrapper import CLIPLoRAWrapper
from lora.lora_config import LoRAConfig

# åˆ›å»ºåŸå§‹è”é‚¦CLIPæ¨¡å‹
original_model = FederatedCLIPModel(
    model_name="openai/clip-vit-base-patch32",
    num_classes=10
)

# åˆ›å»ºLoRAé…ç½®
lora_config = LoRAConfig.for_clip_model(r=16, lora_alpha=32)

# åˆ›å»ºLoRAåŒ…è£…å™¨
lora_wrapper = CLIPLoRAWrapper(
    federated_clip_model=original_model,
    lora_config=lora_config,
    target_components=['encoder']  # åªå¯¹ç¼–ç å™¨åº”ç”¨LoRA
)

# åº”ç”¨LoRA
lora_wrapper.apply_lora_to_federated_model()

# ç°åœ¨original_modelçš„æ¥å£ä¿æŒä¸å˜ï¼Œä½†å†…éƒ¨ä½¿ç”¨LoRA
```

### 3. é…ç½®ç®¡ç†

```python
from lora.lora_config import LoRAConfig
from lora.factory import LoRAConfigManager

# åˆ›å»ºä¸åŒçš„é…ç½®
small_config = LoRAConfig.for_clip_model(r=8, lora_alpha=16)
large_config = LoRAConfig.for_clip_model(r=32, lora_alpha=64)

# ä½¿ç”¨é…ç½®ç®¡ç†å™¨
config_manager = LoRAConfigManager()
config_manager.save_config(small_config, "clip_small")
config_manager.save_config(large_config, "clip_large")

# åŠ è½½é…ç½®
loaded_config = config_manager.load_config("clip_small")
```

### 4. æ¨¡å‹ç®¡ç†

```python
from lora.factory import LoRAModelManager

# åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
model_manager = LoRAModelManager()

# ä¿å­˜LoRAæ¨¡å‹
model_manager.save_model(lora_wrapper, "my_clip_lora_model")

# åŠ è½½LoRAæ¨¡å‹
model_manager.load_model("my_clip_lora_model", lora_wrapper)

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
info = model_manager.get_model_info("my_clip_lora_model")
print(info)
```

## é…ç½®é€‰é¡¹

### LoRAConfig å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `r` | 16 | LoRA rankï¼Œæ§åˆ¶ä½ç§©åˆ†è§£çš„ç»´åº¦ |
| `lora_alpha` | 32 | LoRA scaling å‚æ•° |
| `lora_dropout` | 0.1 | LoRAå±‚çš„dropoutæ¦‚ç‡ |
| `target_modules` | è‡ªåŠ¨æ¨æ–­ | è¦åº”ç”¨LoRAçš„æ¨¡å—åç§° |
| `bias` | "none" | biaså¤„ç†æ–¹å¼ |

### é¢„è®¾é…ç½®

```python
from lora.lora_config import LoRAConfig

# CLIPæ¨¡å‹é…ç½®ï¼ˆä¸åŒè§„æ¨¡ï¼‰
small_config = LoRAConfig.for_clip_model(r=8, lora_alpha=16)   # å°è§„æ¨¡
medium_config = LoRAConfig.for_clip_model(r=16, lora_alpha=32) # ä¸­ç­‰è§„æ¨¡
large_config = LoRAConfig.for_clip_model(r=32, lora_alpha=64)  # å¤§è§„æ¨¡

# åˆ†ç±»å¤´é…ç½®
classifier_config = LoRAConfig.for_classification_head(r=8, lora_alpha=16)
```

## è”é‚¦å­¦ä¹ é›†æˆ

### ä¸ç°æœ‰æ¡†æ¶çš„å…¼å®¹æ€§

LoRAåŒ…è£…å™¨å®Œå…¨å…¼å®¹ç°æœ‰çš„è”é‚¦å­¦ä¹ å‚æ•°ç®¡ç†æ¥å£ï¼š

```python
# è·å–å‚æ•°ï¼ˆè‡ªåŠ¨è¿”å›LoRAå‚æ•°æˆ–å®Œæ•´å‚æ•°ï¼‰
params = model.get_parameters()

# è®¾ç½®å‚æ•°
model.set_parameters(params)

# è®­ç»ƒæ­¥éª¤
loss = model.train_step(data, labels)

# è¯„ä¼°
metrics = model.evaluate(data, labels)
```

### å‚æ•°ä¼ è¾“ä¼˜åŒ–

```python
# é…ç½®ä¸ºåªä¼ è¾“LoRAå‚æ•°ï¼ˆå¤§å¹…å‡å°‘é€šä¿¡å¼€é”€ï¼‰
lora_config = LoRAConfig.for_clip_model(r=16)
lora_config.save_only_trainable = True  # åªä¿å­˜å¯è®­ç»ƒå‚æ•°

# å‚æ•°æ•ˆç‡ç¤ºä¾‹ï¼š
# åŸå§‹CLIPæ¨¡å‹: ~151M å‚æ•°
# LoRA r=16: ~2.4M å‚æ•° (å‡å°‘ 98.4%)
```

## é«˜çº§ç”¨æ³•

### 1. é€‰æ‹©æ€§åº”ç”¨LoRA

```python
# åªå¯¹ç¼–ç å™¨åº”ç”¨LoRA
lora_wrapper = CLIPLoRAWrapper(
    federated_clip_model=model,
    target_components=['encoder']
)

# å¯¹ç¼–ç å™¨å’Œåˆ†ç±»å¤´éƒ½åº”ç”¨LoRA
lora_wrapper = CLIPLoRAWrapper(
    federated_clip_model=model,
    target_components=['encoder', 'classifier']
)
```

### 2. æ¢¯åº¦æ£€æŸ¥ç‚¹

```python
# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜
lora_wrapper.enable_gradient_checkpointing()

# ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
lora_wrapper.disable_gradient_checkpointing()
```

### 3. æƒé‡åˆå¹¶

```python
# å°†LoRAæƒé‡åˆå¹¶åˆ°åŸå§‹æ¨¡å‹
merged_model = lora_wrapper.merge_and_unload()
```

### 4. åŠ¨æ€å¯ç”¨/ç¦ç”¨LoRA

```python
# å¯ç”¨LoRAå±‚
lora_wrapper.enable_lora_layers()

# ç¦ç”¨LoRAå±‚ï¼ˆä½¿ç”¨åŸå§‹æƒé‡ï¼‰
lora_wrapper.disable_lora_layers()
```

## æ€§èƒ½ä¼˜åŠ¿

### å‚æ•°æ•ˆç‡å¯¹æ¯”

| æ¨¡å‹ | æ€»å‚æ•° | å¯è®­ç»ƒå‚æ•° | æ•ˆç‡æ¯” |
|------|---------|------------|--------|
| CLIP-ViT-B/32 (å®Œæ•´) | 151M | 151M | 100% |
| CLIP + LoRA (r=8) | 151M | 1.2M | 0.8% |
| CLIP + LoRA (r=16) | 151M | 2.4M | 1.6% |
| CLIP + LoRA (r=32) | 151M | 4.8M | 3.2% |

### å†…å­˜å’Œé€šä¿¡ä¼˜åŠ¿

- **å†…å­˜å ç”¨**: LoRAåªéœ€å­˜å‚¨ä½ç§©åˆ†è§£çŸ©é˜µï¼Œæ˜¾è‘—é™ä½å†…å­˜éœ€æ±‚
- **é€šä¿¡å¼€é”€**: è”é‚¦å­¦ä¹ ä¸­åªéœ€ä¼ è¾“LoRAå‚æ•°ï¼Œå‡å°‘98%+çš„ç½‘ç»œä¼ è¾“
- **è®­ç»ƒé€Ÿåº¦**: æ›´å°‘çš„å‚æ•°æ›´æ–°ï¼ŒåŠ é€Ÿè®­ç»ƒè¿‡ç¨‹

## æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½ï¼š

```bash
cd lora
python test_lora.py
```

æµ‹è¯•å†…å®¹åŒ…æ‹¬ï¼š
- ä¾èµ–é¡¹æ£€æŸ¥
- é…ç½®ç®¡ç†æµ‹è¯•
- åŒ…è£…å™¨åˆ›å»ºæµ‹è¯•
- å·¥å‚åŠŸèƒ½æµ‹è¯•
- CLIPé›†æˆæµ‹è¯•

## åç»­é›†æˆæ­¥éª¤

è¦å°†LoRAåŠŸèƒ½é›†æˆåˆ°ç°æœ‰é¡¹ç›®ä¸­ï¼Œå»ºè®®æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

### 1. é…ç½®æ–‡ä»¶é›†æˆ

åœ¨ `configs/` ç›®å½•ä¸‹æ·»åŠ LoRAç›¸å…³é…ç½®ï¼š

```yaml
# configs/clip_lora.yaml
model:
  type: "clip_lora"
  model_name: "openai/clip-vit-base-patch32"
  num_classes: 10
  
lora:
  enabled: true
  r: 16
  lora_alpha: 32
  target_components: ["encoder"]
  save_only_trainable: true
```

### 2. æ¨¡å‹å·¥å‚é›†æˆ

åœ¨ `utils/model_factory.py` ä¸­æ·»åŠ LoRAæ¨¡å‹åˆ›å»ºï¼š

```python
def create_model(config):
    if config.model.type == "clip_lora":
        from lora import quick_clip_lora
        return quick_clip_lora(
            model_name=config.model.model_name,
            num_classes=config.model.num_classes,
            lora_r=config.lora.r
        )
    # ... å…¶ä»–æ¨¡å‹ç±»å‹
```

### 3. è®­ç»ƒè„šæœ¬ä¿®æ”¹

ç°æœ‰è®­ç»ƒè„šæœ¬æ— éœ€ä¿®æ”¹ï¼ŒLoRAæ¨¡å‹ä¸åŸå§‹æ¨¡å‹æ¥å£å®Œå…¨å…¼å®¹ã€‚

## æ³¨æ„äº‹é¡¹

1. **ä¾èµ–ç®¡ç†**: ç¡®ä¿å®‰è£…äº† `torch`, `peft`, `transformers`
2. **å†…å­˜ç®¡ç†**: å¤§æ¨¡å‹åº”ç”¨LoRAæ—¶æ³¨æ„æ˜¾å­˜ä½¿ç”¨
3. **é…ç½®å…¼å®¹**: åŠ è½½ä¿å­˜çš„LoRAæƒé‡æ—¶ç¡®ä¿é…ç½®å…¼å®¹
4. **ç‰ˆæœ¬å…¼å®¹**: å»ºè®®ä½¿ç”¨ç¨³å®šç‰ˆæœ¬çš„ä¾èµ–åº“

## è®¸å¯è¯

æœ¬æ¨¡å—éµå¾ªé¡¹ç›®çš„æ•´ä½“è®¸å¯è¯ã€‚