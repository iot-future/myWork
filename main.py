#!/usr/bin/env python3
"""
è”é‚¦å­¦ä¹ å®éªŒå…¥å£æ–‡ä»¶
"""

import yaml
from utils.config_manager import ConfigManager
from utils.experiment_runner import ExperimentRunner
from utils.results_handler import ResultsHandler


def main():
    """ä¸»å‡½æ•° - ç®€æ´çš„å®éªŒæµç¨‹"""
    # åˆ›å»ºé…ç½®ç®¡ç†å™¨
    config_manager = ConfigManager()
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = config_manager.create_parser()
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®å¹¶åº”ç”¨å‘½ä»¤è¡Œè¦†ç›–
    config = config_manager.load_config(args.config)
    config = config_manager.override_config(config, args)
    
    # æ‰“å°å…³é”®é…ç½®ä¿¡æ¯
    print("=" * 60)
    print("ğŸ”§ å®éªŒé…ç½®")
    print("=" * 60)
    print(f"å®éªŒåç§°: {config['experiment']['name']}")
    print(f"è®­ç»ƒè½®æ¬¡: {config['experiment']['rounds']} | å®¢æˆ·ç«¯æ•°é‡: {config['client']['num_clients']} | æœ¬åœ°è®­ç»ƒè½®æ¬¡: {config['client']['local_epochs']}")
    print(f"ä¼˜åŒ–å™¨: AdamW (ç»Ÿä¸€ä½¿ç”¨)")
    
    # æ˜¾ç¤ºLoRAé…ç½®ä¿¡æ¯
    model_config = config.get('model', {})
    lora_config = model_config.get('lora', {})
    if lora_config.get('enabled', False):
        print(f"ğŸ¯ LoRAå¾®è°ƒ: å¯ç”¨ (r={lora_config.get('r', 16)}, alpha={lora_config.get('lora_alpha', 32)})")
    else:
        print(f"ğŸ“¸ è®­ç»ƒæ¨¡å¼: æ ‡å‡†å¾®è°ƒ")
    
    data_info = f"æ‰¹å¤§å°: {config['data']['batch_size']}"
    if config.get('wandb', {}).get('enabled', False):
        data_info += f" | WandBé¡¹ç›®: {config['wandb']['project']}"
    print(data_info)
    print("=" * 60)
    
    # è¿è¡Œå®éªŒ
    print("ğŸš€ å¼€å§‹è¿è¡Œå®éªŒ...")
    print("-" * 60)
    experiment_runner = ExperimentRunner(config)
    results = experiment_runner.run_experiment()
    
    # æ‰“å°ç»“æœæ‘˜è¦
    print()
    print("=" * 60)
    print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
    print("=" * 60)
    ResultsHandler.print_experiment_summary(results)
    print("=" * 60)


if __name__ == '__main__':
    main()
