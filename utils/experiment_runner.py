"""
å®éªŒè¿è¡Œå™¨æ¨¡å—
è´Ÿè´£è”é‚¦å­¦ä¹ å®éªŒçš„è®¾ç½®ã€è¿è¡Œå’Œç»“æœä¿å­˜
"""

import os
import random
import numpy as np
import torch
import time
import sys
from typing import Dict, Any, List
from torch.utils.data import DataLoader, ConcatDataset
from tqdm import tqdm

from core.server import FederatedServer
from core.client import FederatedClient
from data.data_loader import get_client_dataloaders
from aggregation.federated_avg import FederatedAveraging
from utils.model_factory import ModelFactory
from utils.results_handler import ResultsHandler
from utils.wandb_logger import init_wandb, log_client_metrics, log_global_metrics, finish_wandb
from utils.dataset_stats import count_clients_per_dataset
from utils.evaluation_manager import EvaluationManager
from data.data_loader import SUPPORTED_DATASETS
from data.middleware import create_unified_dataloader
from utils.device_manager import device_manager


class ExperimentRunner:
    """
    è”é‚¦å­¦ä¹ å®éªŒè¿è¡Œå™¨
    
    Attributes:
        config (Dict[str, Any]): å®éªŒé…ç½®å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å®éªŒå‚æ•°
        server (FederatedServer): è”é‚¦å­¦ä¹ æœåŠ¡å™¨å®ä¾‹
        clients (List[FederatedClient]): è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯åˆ—è¡¨
        test_loaders (Dict[str, DataLoader]): å„æ•°æ®é›†çš„æµ‹è¯•æ•°æ®åŠ è½½å™¨
        use_wandb (bool): æ˜¯å¦ä½¿ç”¨ Weights & Biases è®°å½•å®éªŒ
        device (torch.device): è®­ç»ƒè®¾å¤‡ï¼ˆCPU/GPUï¼‰
        dataset_client_counts (Dict): å„æ•°æ®é›†çš„å®¢æˆ·ç«¯æ•°é‡ç»Ÿè®¡
        dataset_client_mappings (Dict): æ•°æ®é›†åˆ°å®¢æˆ·ç«¯çš„æ˜ å°„å…³ç³»
    
    Example:
        >>> config = {
        ...     'experiment': {'name': 'fed_avg_mnist', 'rounds': 10, 'seed': 42},
        ...     'model': {'name': 'cnn', 'num_classes': 10},
        ...     'client': {'num_clients': 5, 'local_epochs': 3},
        ...     'data': {'datasets': {'mnist': {}}, 'batch_size': 32}
        ... }
        >>> runner = ExperimentRunner(config)
        >>> results = runner.run_experiment()
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.server = None
        self.clients = []
        self.test_loaders = {}
        self.use_wandb = config.get('wandb', {}).get('enabled', False)
        self.device = None
        self.dataset_client_counts, self.dataset_client_mappings = count_clients_per_dataset(config)
        
        # åˆ›å»ºè¯„ä¼°ç®¡ç†å™¨
        verbose = config.get('evaluation', {}).get('verbose', True)
        self.evaluation_manager = EvaluationManager(verbose=verbose)
        
        # æ—¶é—´è¿½è¸ªå˜é‡
        self.experiment_start_time = None
        self.round_times = []
        self.client_training_times = []

    def setup_environment(self):
        """è®¾ç½®å®éªŒç¯å¢ƒ"""
        # è®¾ç½®è®¾å¤‡
        device_config = self.config.get('device', 'auto')
        self.device = device_manager.get_optimal_device(device_config)

        # è®¾ç½®éšæœºç§å­
        seed = self.config['experiment']['seed']
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)

        if self.device.type == 'cuda':
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
            os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

        os.environ['PYTHONHASHSEED'] = str(seed)
        torch.use_deterministic_algorithms(True)

        print(f"âœ“ ç¯å¢ƒè®¾ç½®å®Œæˆ: éšæœºç§å­ {seed}, è®¾å¤‡ {self.device}")

    def setup_data(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        data_config = self.config['data']  # æ•°æ®é…ç½®
        client_config = self.config['client']  # å®¢æˆ·ç«¯é…ç½®

        # è·å–é…ç½®å‚æ•°
        num_clients = client_config['num_clients']
        batch_size = data_config['batch_size']
        data_root = data_config.get('data_dir', './data')

        # è·å–æ¯ä¸ªæ•°æ®é›†çš„è·¯å¾„ç­‰åŸºæœ¬ä¿¡æ¯
        base_dataset_configs = {
            dataset_name: {'data_root': data_root, **dataset_config}
            for dataset_name, dataset_config in data_config['datasets'].items()
        }

        # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ›å»ºæ•°æ®åŠ è½½å™¨
        client_data_loaders = []
        client_datasets_config = client_config['client_datasets']

        for client_id in range(num_clients):
            client_key = f"client_{client_id}"
            # è·å–è¯¥å®¢æˆ·ç«¯åº”è¯¥ä½¿ç”¨çš„æ•°æ®é›†åˆ—è¡¨
            client_dataset_names = client_datasets_config[client_key]

            # ä¸ºæ­¤å®¢æˆ·ç«¯å‡†å¤‡æ•°æ®é›†é…ç½®
            client_dataset_configs = {
                name: base_dataset_configs[name]
                for name in client_dataset_names
                if name in base_dataset_configs
            }

            # è·å–æ­¤å®¢æˆ·ç«¯çš„æ•°æ®åŠ è½½å™¨
            client_dataloaders_dict = get_client_dataloaders(
                client_original_id=client_key,
                dataset_client_mappings=self.dataset_client_mappings,
                dataset_client_counts=self.dataset_client_counts,
                batch_size=batch_size,
                dataset_configs=client_dataset_configs,
                seed=self.config['experiment']['seed']
            )

            client_data_loaders.append(client_dataloaders_dict)

        # åˆ›å»ºå¤šæ•°æ®é›†æµ‹è¯•æ•°æ®åŠ è½½å™¨
        self.test_loaders = self._create_test_loaders(base_dataset_configs, batch_size)

        # è®¡ç®—å¹¶æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        self._print_data_statistics(client_data_loaders, num_clients)

        # æ‰“å°æµ‹è¯•é›†ä¿¡æ¯
        if self.test_loaders:
            print(f"\nâœ“ æµ‹è¯•æ•°æ®é›† ({len(self.test_loaders)} ä¸ª):")
        else:
            print("\nâš ï¸  æ— å¯ç”¨æµ‹è¯•æ•°æ®é›†")

        return client_data_loaders

    def _create_test_loaders(self, base_dataset_configs: Dict[str, Dict], batch_size: int) -> Dict[str, DataLoader]:
        """åˆ›å»ºå¤šæ•°æ®é›†æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        test_loaders = {}
        
        for dataset_name, dataset_config in base_dataset_configs.items():
            # åˆ›å»ºæµ‹è¯•é…ç½®
            test_config = dataset_config.copy()
            test_config['train'] = False
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®é›†å®ä¾‹
            test_dataset = SUPPORTED_DATASETS[dataset_name](**test_config)
            
            # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
            raw_test_loader = DataLoader(
                test_dataset, 
                batch_size=batch_size, 
                shuffle=False,
                num_workers=0
            )
            
            # ä½¿ç”¨ä¸­é—´ä»¶åˆ›å»ºç»Ÿä¸€æ ¼å¼çš„æµ‹è¯•æ•°æ®åŠ è½½å™¨
            test_loaders[dataset_name] = create_unified_dataloader(raw_test_loader, dataset_name.lower())
            print(f"  âœ“ {dataset_name} æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
            
        return test_loaders
    
    def _prepare_test_config(self, dataset_config: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡æµ‹è¯•æ•°æ®é›†é…ç½®"""
        test_config = dataset_config.copy()
        test_config['train'] = False
        return test_config

    def _print_data_statistics(self, client_data_loaders, num_clients):
        """æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {num_clients} ä¸ªå®¢æˆ·ç«¯")

        for client_id, dataloaders_dict in enumerate(client_data_loaders):
            dataset_info = []
            total_client_samples = 0

            for dataset_name, dataloader in dataloaders_dict.items():
                samples = len(dataloader.dataset)
                total_client_samples += samples
                dataset_info.append(f"{dataset_name}({samples})")

            datasets_str = ", ".join(dataset_info)
            print(f"  å®¢æˆ·ç«¯ {client_id}: {datasets_str} - æ€»è®¡ {total_client_samples} æ ·æœ¬")

    def setup_server(self):
        """è®¾ç½®æœåŠ¡å™¨"""
        optimizer_config = self.config.get('optimizer', {})
        global_model = ModelFactory.create_model(
            self.config['model'],
            optimizer_config if optimizer_config else None
        )

        # å°†æ¨¡å‹ç§»åˆ°è®¾å¤‡
        global_model = device_manager.move_model_to_device(global_model, self.device)
        
        # æ·»åŠ LoRAçŠ¶æ€éªŒè¯
        if hasattr(global_model, 'is_lora_enabled') and global_model.is_lora_enabled():
            lora_info = global_model.get_lora_info()
            print(f"ğŸ¯ å…¨å±€æ¨¡å‹LoRAçŠ¶æ€: å·²å¯ç”¨ | å¯è®­ç»ƒå‚æ•°: {lora_info.get('trainable_parameters', 0):,}")
        elif hasattr(global_model, 'is_lora_enabled'):
            print("ğŸ“¸ å…¨å±€æ¨¡å‹: æ ‡å‡†å¾®è°ƒæ¨¡å¼")

        # åˆ›å»ºèšåˆå™¨å’ŒæœåŠ¡å™¨
        aggregator = FederatedAveraging()
        self.server = FederatedServer(global_model, aggregator)
        print("âœ“ æœåŠ¡å™¨è®¾ç½®å®Œæˆ")

    def setup_clients(self, client_data_loaders: List):
        """è®¾ç½®å®¢æˆ·ç«¯"""
        client_config = self.config['client']
        optimizer_config = self.config.get('optimizer', {})
        
        print(f"\nğŸ”§ å¼€å§‹è®¾ç½® {len(client_data_loaders)} ä¸ªå®¢æˆ·ç«¯...")

        self.clients = []
        lora_clients_count = 0
        
        for i, dataloaders_dict in enumerate(client_data_loaders):
            client_id = f"client_{i}"
            client_model = ModelFactory.create_model(
                self.config['model'],
                optimizer_config if optimizer_config else None
            )

            # å°†å®¢æˆ·ç«¯æ¨¡å‹ç§»åˆ°è®¾å¤‡
            client_model = device_manager.move_model_to_device(client_model, self.device)
            
            # ç»Ÿè®¡LoRAå¯ç”¨çš„å®¢æˆ·ç«¯æ•°é‡
            if hasattr(client_model, 'is_lora_enabled') and client_model.is_lora_enabled():
                lora_clients_count += 1

            # å¤„ç†æ•°æ®åŠ è½½å™¨ï¼šå•æ•°æ®é›†æˆ–å¤šæ•°æ®é›†
            data_loader = (list(dataloaders_dict.values())[0] if len(dataloaders_dict) == 1
                           else self._create_combined_dataloader(dataloaders_dict))

            client = FederatedClient(
                client_id=client_id,
                model=client_model,
                data_loader=data_loader,
                epochs=client_config['local_epochs'],
                learning_rate=client_config.get('learning_rate', optimizer_config.get('learning_rate', 0.01)),
                device=self.device
            )
            self.clients.append(client)

        print(f"âœ“ å®¢æˆ·ç«¯è®¾ç½®å®Œæˆ: {len(self.clients)} ä¸ªå®¢æˆ·ç«¯")
        if lora_clients_count > 0:
            print(f"ğŸ¯ LoRAå¯ç”¨å®¢æˆ·ç«¯: {lora_clients_count}/{len(self.clients)}")

    def _create_combined_dataloader(self, dataloaders_dict):
        """åˆ›å»ºè”åˆæ•°æ®åŠ è½½å™¨ï¼Œå°†å¤šä¸ªæ•°æ®é›†åˆå¹¶ä¸ºä¸€ä¸ªæ•°æ®åŠ è½½å™¨"""
        datasets = [dataloader.dataset for dataloader in dataloaders_dict.values()]
        combined_dataset = ConcatDataset(datasets)

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®åŠ è½½å™¨çš„é…ç½®å‚æ•°
        first_loader = list(dataloaders_dict.values())[0]

        return DataLoader(
            combined_dataset,
            batch_size=first_loader.batch_size,
            shuffle=True,
            num_workers=0
        )

    def run_federated_round(self, round_num: int) -> Dict[str, float]:
        """æ‰§è¡Œä¸€è½®è”é‚¦å­¦ä¹ """
        round_start_time = time.time()
        
        # è·å–å…¨å±€æ¨¡å‹å‚æ•°
        global_params = self.server.send_global_model()

        # æ‰€æœ‰å®¢æˆ·ç«¯è¿›è¡Œæœ¬åœ°è®­ç»ƒ - ä½¿ç”¨åµŒå¥—çš„è¿›åº¦æ¡
        client_updates = []
        
        # æ£€æŸ¥æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿›åº¦ï¼ˆbatchçº§åˆ«ï¼‰
        show_batch_progress = self.config.get('training', {}).get('show_batch_progress', True)
        
        with tqdm(self.clients, desc=f"ç¬¬{round_num}è½®è®­ç»ƒ", 
                  bar_format="{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]",
                  ncols=None, leave=False, position=1, file=sys.stdout) as pbar:
            
            for i, client in enumerate(pbar):
                # ä¼ é€’show_progresså‚æ•°ä»¥å¯ç”¨batchçº§åˆ«çš„è¿›åº¦æ¡
                client_result = client.train(global_params, show_progress=show_batch_progress)
                client_updates.append(client_result)
                
                # ç®€åŒ–çš„è¿›åº¦ä¿¡æ¯
                loss = client_result.get('metrics', {}).get('loss', 0)
                pbar.set_postfix({'Loss': f'{loss:.3f}'})
                
                # åˆ·æ–°æ˜¾ç¤ºä»¥é¿å…é‡å 
                pbar.refresh()

                # è®°å½•å®¢æˆ·ç«¯æŒ‡æ ‡åˆ°wandb
                if self.use_wandb and 'metrics' in client_result:
                    metrics = client_result['metrics']
                    log_client_metrics(
                        client.client_id,
                        round_num,
                        metrics.get('loss', 0.0),
                        metrics.get('accuracy')
                    )

        # æœåŠ¡å™¨èšåˆ
        self.server.aggregate(client_updates)

        # è¯„ä¼°ï¼ˆä½¿ç”¨æ–°çš„è¯„ä¼°ç®¡ç†å™¨ï¼‰
        metrics = {}
        if round_num % self.config['evaluation']['evaluate_every'] == 0:
            # è¯„ä¼°å®¢æˆ·ç«¯æœ¬åœ°æ¨¡å‹
            client_metrics = self.evaluation_manager.evaluate_clients(self.clients, round_num)
            
            # è¯„ä¼°å…¨å±€æ¨¡å‹
            global_metrics = self.evaluation_manager.evaluate_global_model(
                self.server, self.test_loaders, round_num
            )
            
            # åˆ›å»ºè¯„ä¼°ç»“æœ
            eval_result = self.evaluation_manager.create_evaluation_result(
                round_num, client_metrics, global_metrics
            )
            
            # æ‰“å°è½®æ¬¡æ€»ç»“
            progress_msg = self.evaluation_manager.format_round_summary(eval_result)
            print(progress_msg)
            
            # è®°å½•å…¨å±€æ¨¡å‹æŒ‡æ ‡åˆ°wandb
            if self.use_wandb and global_metrics:
                log_global_metrics(round_num, global_metrics)
                
            metrics = global_metrics

        return metrics

    def run_experiment(self) -> List[Dict[str, Any]]:
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print(f"å¼€å§‹å®éªŒ: {self.config['experiment']['name']}")
        print("=" * 60)

        # åˆå§‹åŒ–wandb
        if self.use_wandb:
            project_name = self.config.get('wandb', {}).get('project', 'federated-learning')
            is_offline = self.config.get('wandb', {}).get('offline', False)
            init_wandb(self.config, project_name, is_offline)

        # è®¾ç½®å®éªŒç¯å¢ƒ
        self.setup_environment()

        # è®¾ç½®æ•°æ®
        client_data_loaders = self.setup_data()

        # è®¾ç½®æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
        self.setup_server()
        self.setup_clients(client_data_loaders)

        print("\nå¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ...")
        # è¿è¡Œè”é‚¦å­¦ä¹ è½®æ¬¡
        rounds = self.config['experiment']['rounds']
        all_metrics = []
        self.experiment_start_time = time.time()
        
        # åœ¨è®­ç»ƒå¼€å§‹å‰è®°å½•LoRAå‚æ•°çŠ¶æ€ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        lora_enabled = hasattr(self.server.global_model, 'is_lora_enabled') and self.server.global_model.is_lora_enabled()
        if lora_enabled:
            initial_lora_params = self.server.global_model.get_parameters()
            lora_param_count = len([k for k in initial_lora_params.keys() if 'lora_' in k])
            print(f"ğŸ”„ LoRAè®­ç»ƒæ¨¡å¼: {lora_param_count} ä¸ªLoRAå‚æ•°å±‚å°†è¢«ä¼˜åŒ–")

        # ä½¿ç”¨æ€»ä½“è¿›åº¦æ¡
        with tqdm(range(1, rounds + 1), desc="å®éªŒè¿›åº¦", unit="è½®", 
                  position=0, file=sys.stdout, ncols=None) as round_pbar:
            for round_num in round_pbar:
                metrics = self.run_federated_round(round_num)
                if metrics:
                    metrics['round'] = round_num
                    all_metrics.append(metrics)
                
                # æ›´æ–°æ€»ä½“è¿›åº¦æ¡
                if metrics and 'accuracy' in metrics:
                    round_pbar.set_postfix({'Acc': f"{metrics['accuracy']:.2f}%"})
                
                # åœ¨æœ€åä¸€è½®éªŒè¯LoRAå‚æ•°æ›´æ–°
                if lora_enabled and round_num == rounds:
                    current_lora_params = self.server.global_model.get_parameters()
                    lora_keys = [k for k in current_lora_params.keys() if 'lora_' in k]
                    print(f"âœ… LoRAè®­ç»ƒå®Œæˆ: {len(lora_keys)} ä¸ªå‚æ•°å±‚å·²ä¼˜åŒ–")

        # æ‰“å°æœ€ç»ˆæ€»ç»“
        self._print_final_summary()

        print("=" * 60)
        print("âœ… å®éªŒå®Œæˆ!")

        # ç»“æŸwandbè®°å½•
        if self.use_wandb:
            finish_wandb()

        return all_metrics
    
    def _print_final_summary(self):
        """æ‰“å°æœ€ç»ˆå®éªŒæ€»ç»“"""
        summary = self.evaluation_manager.get_final_summary()
        if not summary:
            print("âš ï¸  æ²¡æœ‰å¯ç”¨çš„å®éªŒç»“æœ")
            return
            
        print(f"\nğŸ“Š å®éªŒæ€»ç»“:")
        print(f"æ€»è®­ç»ƒè½®æ¬¡: {summary['total_rounds']}")
        print(f"æœ€ç»ˆå‡†ç¡®ç‡: {summary['final_accuracy']:.2f}%")
        print(f"æœ€ç»ˆæŸå¤±: {summary['final_loss']:.4f}")
        
        if summary['total_rounds'] > 1:
            print(f"å‡†ç¡®ç‡æå‡: +{summary['accuracy_improvement']:.2f}%")
            print(f"æŸå¤±é™ä½: -{summary['loss_reduction']:.4f}")
            
        print(f"å‚ä¸å®¢æˆ·ç«¯: {summary['client_count']} ä¸ª")
