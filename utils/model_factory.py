"""
æ¨¡å‹å·¥å‚æ¨¡å—
è´Ÿè´£æ ¹æ®é…ç½®åˆ›å»ºä¸åŒç±»å‹çš„æ¨¡å‹ï¼Œæ”¯æŒé…ç½®åŒ–ä¼˜åŒ–å™¨
"""

from typing import Dict, Any, Optional, List
from models.cnn import FederatedCNNModel
from models.base import FederatedLinearModel
from models.clip import FederatedCLIPModel


class ModelFactory:
    """æ¨¡å‹å·¥å‚ç±»"""

    @staticmethod
    def create_model(model_config: Dict[str, Any], optimizer_config: Optional[Dict[str, Any]] = None,
                     dataset_name: Optional[List[str]] = None):
        """
        æ ¹æ®é…ç½®åˆ›å»ºæ¨¡å‹
        
        Args:
            model_config: æ¨¡å‹é…ç½®å­—å…¸
            optimizer_config: ä¼˜åŒ–å™¨é…ç½®å­—å…¸
            dataset_name: æ‰€ç”¨çš„æ•°æ®é›†
            
        Returns:
            é…ç½®å¥½çš„æ¨¡å‹å®ä¾‹
        """
        model_type = model_config['type']

        if model_type == 'cnn':
            return FederatedCNNModel(optimizer_config=optimizer_config)
        elif model_type == 'linear':
            # çº¿æ€§æ¨¡å‹éœ€è¦é¢å¤–çš„ç»´åº¦å‚æ•°
            input_dim = model_config.get('input_dim', 784)  # MNISTé»˜è®¤28*28
            output_dim = model_config.get('output_dim', 10)  # 10ä¸ªç±»åˆ«
            return FederatedLinearModel(
                input_dim=input_dim,
                output_dim=output_dim,
                optimizer_config=optimizer_config
            )
        elif model_type == 'clip':
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LoRA
            lora_config = model_config.get('lora', {})
            if lora_config.get('enabled', False):
                print(f"ğŸ”¬ CLIPæ¨¡å‹å¯ç”¨LoRAå¾®è°ƒ (r={lora_config.get('r', 16)})")

            # åŸºäºHugging Faceçš„CLIPæ¨¡å‹
            return FederatedCLIPModel(
                model_name=model_config.get('model_name', 'openai/clip-vit-base-patch32'),
                num_classes=model_config.get('num_classes', 10),
                normalize_features=model_config.get('normalize_features', True),
                freeze_encoder=model_config.get('freeze_vision_encoder', False),
                cache_dir=model_config.get('cache_dir', None),
                optimizer_config=optimizer_config,
                lora_config=lora_config if lora_config.get('enabled', False) else None,
                dataset_name=dataset_name
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

    @staticmethod
    def get_supported_models():
        """è·å–æ”¯æŒçš„æ¨¡å‹ç±»å‹åˆ—è¡¨"""
        return ['cnn', 'linear', 'clip']

    @staticmethod
    def get_model_info(model_type: str) -> Dict[str, Any]:
        """
        è·å–ç‰¹å®šæ¨¡å‹ç±»å‹çš„ä¿¡æ¯
        
        Args:
            model_type: æ¨¡å‹ç±»å‹
            
        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        if model_type == 'cnn':
            return {
                'name': 'CNNæ¨¡å‹',
                'description': 'å·ç§¯ç¥ç»ç½‘ç»œï¼Œé€‚ç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡',
                'required_params': [],
                'optional_params': ['optimizer_config']
            }
        elif model_type == 'linear':
            return {
                'name': 'çº¿æ€§æ¨¡å‹',
                'description': 'ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œ',
                'required_params': [],
                'optional_params': ['input_dim', 'output_dim', 'optimizer_config']
            }
        elif model_type == 'clip':
            return {
                'name': 'CLIPæ¨¡å‹',
                'description': 'åŸºäºHugging Faceçš„CLIPè§†è§‰-è¯­è¨€å¤šæ¨¡æ€æ¨¡å‹',
                'required_params': [],
                'optional_params': [
                    'model_name', 'num_classes', 'normalize_features',
                    'freeze_vision_encoder', 'cache_dir', 'optimizer_config'
                ]
            }
        else:
            return {
                'name': 'æœªçŸ¥æ¨¡å‹',
                'description': 'ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹',
                'required_params': [],
                'optional_params': []
            }
